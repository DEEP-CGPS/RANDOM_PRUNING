{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2177c1",
   "metadata": {},
   "source": [
    "## 1- Definition of arguments for function usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38d2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from utils import *\n",
    "import argparse\n",
    "sys.argv = ['']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Parameters training')\n",
    "parser.add_argument('--model_architecture', type=str, default=\"VGG16\", help='....')\n",
    "parser.add_argument('--dataset', type=str, default=\"CIFAR10\", help='....')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='....')\n",
    "parser.add_argument('--num_epochs', type=int, default=40, help='....')\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3, help='....')\n",
    "parser.add_argument('--optimizer_val', type=str, default=\"SGD\", help='....')\n",
    "parser.add_argument('--model_type', type=str, default=\"UNPRUNED\", help='....')\n",
    "parser.add_argument('--device', type=str, default=None, help='....')\n",
    "parser.add_argument('--model_input', default=torch.ones((1, 3, 224, 224)), help='....')\n",
    "parser.add_argument('--eval_metric', default=\"accuracy\", help='....')\n",
    "parser.add_argument('--pruning_seed', type=int, default=23, help='....')\n",
    "parser.add_argument('--list_pruning', type=list, default = [0.6,0.6,0.53,0.53,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6,0.5,0.5,0], help='....')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.device is None:\n",
    "    import torch\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83c6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for training and pruning\n",
    "#args.model_architecture = \"ResNet18\"\n",
    "#args.num_epochs = 40\n",
    "args.dataset = \"Tomato_Leaves\"\n",
    "args.eval_metric = \"f1_score\"\n",
    "\n",
    "# Modify for pruning\n",
    "args.list_pruning = [0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0]\n",
    "type_pruning = 'HOMOGENEA'\n",
    "base_percentage = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e39dd0",
   "metadata": {},
   "source": [
    "## Get Model, DATASET and TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52085222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, num_classes = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f33976",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(args, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28d3408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/40]\t || Training Loss: 0.373\t || Val Loss: 0.154\t || Training F1-score: 0.863 \t ||  Val F1-score: 0.943 \t || Time: 00:07:12\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [2/40]\t || Training Loss: 0.073\t || Val Loss: 0.031\t || Training F1-score: 0.971 \t ||  Val F1-score: 0.989 \t || Time: 00:14:39\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [3/40]\t || Training Loss: 0.039\t || Val Loss: 0.028\t || Training F1-score: 0.985 \t ||  Val F1-score: 0.990 \t || Time: 00:22:05\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [4/40]\t || Training Loss: 0.029\t || Val Loss: 0.052\t || Training F1-score: 0.989 \t ||  Val F1-score: 0.982 \t || Time: 00:29:25\n",
      "Epoch: [5/40]\t || Training Loss: 0.018\t || Val Loss: 0.116\t || Training F1-score: 0.992 \t ||  Val F1-score: 0.955 \t || Time: 00:36:50\n",
      "Epoch: [6/40]\t || Training Loss: 0.016\t || Val Loss: 0.041\t || Training F1-score: 0.994 \t ||  Val F1-score: 0.985 \t || Time: 00:44:07\n",
      "Epoch: [7/40]\t || Training Loss: 0.016\t || Val Loss: 0.038\t || Training F1-score: 0.993 \t ||  Val F1-score: 0.986 \t || Time: 00:51:44\n",
      "Epoch: [8/40]\t || Training Loss: 0.010\t || Val Loss: 0.021\t || Training F1-score: 0.995 \t ||  Val F1-score: 0.993 \t || Time: 00:59:02\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [9/40]\t || Training Loss: 0.006\t || Val Loss: 0.017\t || Training F1-score: 0.997 \t ||  Val F1-score: 0.995 \t || Time: 01:06:31\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [10/40]\t || Training Loss: 0.009\t || Val Loss: 0.026\t || Training F1-score: 0.997 \t ||  Val F1-score: 0.990 \t || Time: 01:13:48\n",
      "Epoch: [11/40]\t || Training Loss: 0.008\t || Val Loss: 0.026\t || Training F1-score: 0.997 \t ||  Val F1-score: 0.994 \t || Time: 01:21:11\n",
      "Epoch: [12/40]\t || Training Loss: 0.009\t || Val Loss: 0.019\t || Training F1-score: 0.997 \t ||  Val F1-score: 0.995 \t || Time: 01:28:25\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [13/40]\t || Training Loss: 0.004\t || Val Loss: 0.018\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.994 \t || Time: 01:35:53\n",
      "Epoch: [14/40]\t || Training Loss: 0.002\t || Val Loss: 0.022\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.994 \t || Time: 01:43:10\n",
      "Epoch: [15/40]\t || Training Loss: 0.005\t || Val Loss: 0.024\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.991 \t || Time: 01:50:35\n",
      "Epoch: [16/40]\t || Training Loss: 0.004\t || Val Loss: 0.023\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.994 \t || Time: 01:57:54\n",
      "Epoch: [17/40]\t || Training Loss: 0.001\t || Val Loss: 0.020\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.994 \t || Time: 02:05:17\n",
      "Epoch: [18/40]\t || Training Loss: 0.004\t || Val Loss: 0.023\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.994 \t || Time: 02:12:36\n",
      "Epoch: [19/40]\t || Training Loss: 0.002\t || Val Loss: 0.024\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.993 \t || Time: 02:20:01\n",
      "Epoch: [20/40]\t || Training Loss: 0.002\t || Val Loss: 0.026\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.993 \t || Time: 02:27:19\n",
      "Epoch: [21/40]\t || Training Loss: 0.003\t || Val Loss: 0.024\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.993 \t || Time: 02:34:43\n",
      "Epoch: [22/40]\t || Training Loss: 0.008\t || Val Loss: 0.025\t || Training F1-score: 0.996 \t ||  Val F1-score: 0.993 \t || Time: 02:42:05\n",
      "Epoch: [23/40]\t || Training Loss: 0.003\t || Val Loss: 0.022\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.995 \t || Time: 02:49:29\n",
      "Epoch: [24/40]\t || Training Loss: 0.002\t || Val Loss: 0.019\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.993 \t || Time: 02:56:46\n",
      "Epoch: [25/40]\t || Training Loss: 0.004\t || Val Loss: 0.066\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.980 \t || Time: 03:04:07\n",
      "Epoch: [26/40]\t || Training Loss: 0.002\t || Val Loss: 0.016\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.996 \t || Time: 03:11:25\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [27/40]\t || Training Loss: 0.005\t || Val Loss: 0.019\t || Training F1-score: 0.998 \t ||  Val F1-score: 0.995 \t || Time: 03:18:53\n",
      "Epoch: [28/40]\t || Training Loss: 0.001\t || Val Loss: 0.022\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.994 \t || Time: 03:26:09\n",
      "Epoch: [29/40]\t || Training Loss: 0.000\t || Val Loss: 0.017\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.995 \t || Time: 03:33:31\n",
      "Epoch: [30/40]\t || Training Loss: 0.000\t || Val Loss: 0.017\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.996 \t || Time: 03:40:47\n",
      "Model Name: VGG16_Tomato_Leaves_UNPRUNED\n",
      "Epoch: [31/40]\t || Training Loss: 0.001\t || Val Loss: 0.019\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.995 \t || Time: 03:48:13\n",
      "Epoch: [32/40]\t || Training Loss: 0.000\t || Val Loss: 0.017\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.995 \t || Time: 03:55:30\n",
      "Epoch: [33/40]\t || Training Loss: 0.002\t || Val Loss: 0.022\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.994 \t || Time: 04:02:52\n",
      "Epoch: [34/40]\t || Training Loss: 0.001\t || Val Loss: 0.022\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.994 \t || Time: 04:10:08\n",
      "Epoch: [35/40]\t || Training Loss: 0.002\t || Val Loss: 0.018\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.994 \t || Time: 04:17:29\n",
      "Epoch: [36/40]\t || Training Loss: 0.003\t || Val Loss: 0.024\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.994 \t || Time: 04:24:47\n",
      "Epoch: [37/40]\t || Training Loss: 0.001\t || Val Loss: 0.021\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.994 \t || Time: 04:32:08\n",
      "Epoch: [38/40]\t || Training Loss: 0.002\t || Val Loss: 0.023\t || Training F1-score: 0.999 \t ||  Val F1-score: 0.993 \t || Time: 04:39:27\n",
      "Epoch: [39/40]\t || Training Loss: 0.001\t || Val Loss: 0.036\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.992 \t || Time: 04:46:47\n",
      "Epoch: [40/40]\t || Training Loss: 0.001\t || Val Loss: 0.025\t || Training F1-score: 1.000 \t ||  Val F1-score: 0.994 \t || Time: 04:54:04\n"
     ]
    }
   ],
   "source": [
    "train_model(args,\n",
    "            train_loader = train_loader,\n",
    "            test_loader = test_loader,\n",
    "            model = model,\n",
    "            num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4afb3",
   "metadata": {},
   "source": [
    "## Pruning with multiple seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe716f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629f836d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/40]\t || Training Loss: 0.601\t || Val Loss: 0.333\t || Training F1-score: 0.756 \t ||  Val F1-score: 0.851 \t || Time: 00:02:46\n",
      "Model Name: VGG16_Tomato_Leaves_HOMOGENEA_50_PRUNED_FT_SEED_23\n",
      "Epoch: [2/40]\t || Training Loss: 0.183\t || Val Loss: 0.095\t || Training F1-score: 0.923 \t ||  Val F1-score: 0.962 \t || Time: 00:05:33\n",
      "Model Name: VGG16_Tomato_Leaves_HOMOGENEA_50_PRUNED_FT_SEED_23\n",
      "Epoch: [3/40]\t || Training Loss: 0.124\t || Val Loss: 0.098\t || Training F1-score: 0.950 \t ||  Val F1-score: 0.951 \t || Time: 00:08:22\n",
      "Epoch: [4/40]\t || Training Loss: 0.083\t || Val Loss: 0.071\t || Training F1-score: 0.964 \t ||  Val F1-score: 0.975 \t || Time: 00:11:14\n",
      "Model Name: VGG16_Tomato_Leaves_HOMOGENEA_50_PRUNED_FT_SEED_23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22336\\687069153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{type_pruning}_{base_percentage}_PRUNED_FT_SEED_{seed}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#retraining pruned model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     train_model(args,\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\JupyterArchives\\AuxiliarInvestigacion\\RANDOM_PRUNING\\utils\\train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(args, train_loader, test_loader, model, num_classes)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"f1_score\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_f1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_f1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\JupyterArchives\\AuxiliarInvestigacion\\RANDOM_PRUNING\\utils\\train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, data_loader, criterion, optimizer, eval_metric, num_classes)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtrain_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_seeds = [23,42,97,112,167,214,256,333,425,512]\n",
    "\n",
    "original_model_name = f'{args.model_architecture}_{args.dataset}_UNPRUNED'\n",
    "for seed in list_seeds:\n",
    "    #load original model\n",
    "    model = torch.load(f'models/{original_model_name}.pth')\n",
    "    args.seed = seed\n",
    "    args.model_type = f'{type_pruning}_{base_percentage}_PRUNED_SEED_{seed}'\n",
    "    #prune original model\n",
    "    prune_model(model, args)\n",
    "    args.model_type = f'{type_pruning}_{base_percentage}_PRUNED_FT_SEED_{seed}'\n",
    "    #retraining pruned model\n",
    "    train_model(args,\n",
    "                train_loader = train_loader,\n",
    "                test_loader = test_loader,\n",
    "                model = model,\n",
    "                num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b747200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
